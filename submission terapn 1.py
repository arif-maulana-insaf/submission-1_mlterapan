# -*- coding: utf-8 -*-
"""capstone supervised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QyGjcAeBjxO_pm9YTZCsbPP7fZgV1-6y

# prediksi popularitas tempat wisata di indonesia berdasarkan karakteristik

## Business Understanding
### Problem Statements

Menjelaskan pernyataan masalah latar belakang:
- bagaimana cara tempat wisata populer di indonesia berdasarkan data rating dan jumlah review
- bagaimana cara memanfaatkan data kategorikal (kategori dan provinsi) dalam membangun model klasifikasi popularitas

### Goals

Menjelaskan tujuan dari pernyataan masalah:
- Mengembangkan model klasifikasi untuk memprediksi apakah sebuah tempat wisata populer atau tidak
- menggunakan informasi kategori dan provinsi untuk memperkaya fitur input bagi model prediktif

# Data Understanding
adalah tahap proses analysis data yang bertujuan untuk memahami dataset secara mendalam
# data loading
saya menggunakan teknik scraping untuk mendapatkan dataset tersebut, pada tersebut terdapat 1169 baris dan 11 kolom yang saya simpan di [github_saya](https://github.com/arif-maulana-insaf/submission-1_mlterapan)

### import data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE  # Untuk handle class imbalance
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
import joblib
import ast

"""### load data"""

df = pd.read_csv('tempat_wisata_indonesia.csv')
df.info()

"""### explore data

- id = nomor urutan
- nama = nama tempat
- alamat = alamat tempat
- rating = rating tempat
- jumlah review = jumlah review dari lokasi
- deskripsi = dekripsi tempat
- koordinat = titik lokasi
- url = link lokasi di maps
- provinsi = lokasi provinsi
- foto = foto lokasi
- kategori = kategori wisata
"""

df.isnull().sum()

"""dapat kita lihat terdapat data yang kosong pada column alamat, rating, dan jumlah review"""

df.dropna(inplace=True)
df.info()

"""setelah di hapus jumlah data menjadi (1167)"""

df.drop(columns=['id', 'koordinat', 'url','foto'],inplace=True)
df.info()

"""menghapus column yang tidak dibutuhkan yaitu 1 int yaitu id dan 3 object yaitu koordinat, url, dan foto"""

df.describe()

df.duplicated().sum()

"""dapat kita lihat bahwa tidak ada duplikat pada data

#EDA(exploratory data analysis)

## eda multivariate
"""

kategori_exploded = df.explode('kategori')
mean_rating_kategori = kategori_exploded.groupby('kategori')['rating'].mean().sort_values()

plt.figure(figsize=(10,6))
mean_rating_kategori.plot(kind='barh', color='coral')
plt.title('Rata-rata Rating per Kategori')
plt.xlabel('Rating Rata-rata')
plt.ylabel('Kategori')
plt.show()

# rata-rata rating per provinsi
mean_rating_prov = df.groupby('provinsi')['rating'].mean().sort_values()

plt.figure(figsize=(10,6))
mean_rating_prov.plot(kind='barh', color='teal')
plt.title('Rata-rata Rating per Provinsi')
plt.xlabel('Rating Rata-rata')
plt.ylabel('Provinsi')
plt.show()

"""## eda univariate"""

#eda univariate
plt.figure(figsize=(8,4))
sns.histplot(df['rating'], bins=20, kde=True, color='skyblue')
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.show()

plt.figure(figsize=(10,5))
kategori_list = df['kategori'].explode()
sns.countplot(y=kategori_list, order=kategori_list.value_counts().index, palette='cool')
plt.title('Frekuensi Kategori Tempat Wisata')
plt.xlabel('Jumlah')
plt.ylabel('Kategori')
plt.show()

plt.figure(figsize=(12,5))
sns.countplot(y=df['provinsi'], order=df['provinsi'].value_counts().index, palette='mako')
plt.title('Frekuensi Tempat Wisata per Provinsi')
plt.xlabel('Jumlah')
plt.ylabel('Provinsi')
plt.show()

"""## data preparation"""

df['log_jumlah_review'] = np.log1p(df['jumlah_review'])

"""karena terjadinya outlier yang sangat extreme untuk menormalisasikannya saya menggunakan "log tranformasi" agar saya dapat mempertahankan data tersebut"""

numerical = ['rating','jumlah_review','log_jumlah_review']
kategorical =['nama','alamat','deskripsi','provinsi','kategori']

"""memasukan colomn numerik ke varibel numerik dan memasukan colomn str/object ke kategorikal"""

selected_cols = df[numerical]

Q1 = selected_cols.quantile(0.25)
Q3 = selected_cols.quantile(0.75)
IQR = Q3 - Q1

df_filtered = df[~((selected_cols < (Q1 - 1.5 * IQR)) | (selected_cols > (Q3 + 1.5 * IQR))).any(axis=1)]

"""menerapkan metode iqr untuk untuk membuang outlier dan memasukannya ke df_filtered"""

def safe_eval(x):
    try:
        return ast.literal_eval(x) if isinstance(x, str) else []
    except:
      return []

df_filtered.loc[:, 'kategori'] = df_filtered['kategori'].apply(safe_eval)
print("Contoh data kategori:", df_filtered['kategori'].head())

"""membuat fungsi untuk mengubah string yang di represetasikan oleh list python menjadi objek list python asli secara aman yang mana bertujuan untuk di proses lebih lanjut"""

for num in numerical:
    plt.figure(figsize=(7,4))
    sns.boxplot(data=df, x=num, color='blue')
    plt.title(f"boxplot{num}")
    plt.xlabel(num)
    plt.show()

"""melihat boxplot outlier pada numerikal"""

df.describe()

"""hasil yang lebih stabil dari rating dan log_jumlah_review"""

mlb = MultiLabelBinarizer()

if df_filtered['kategori'].explode().notna().sum() > 0:
    kategori_encoded = mlb.fit_transform(df_filtered['kategori'])
    kategori_encoded_df = pd.DataFrame(kategori_encoded, columns=mlb.classes_)


    df_filtered = df_filtered.reset_index(drop=True)
    kategori_encoded_df = kategori_encoded_df.reset_index(drop=True)
    df_filtered = pd.concat([df_filtered, kategori_encoded_df], axis=1)
else:
    print(" Data kategori kosong atau tidak valid.")

df_filtered.info()

"""dari hasil fungsi safe_eval sebelumnya pada column kategori lalu di ubah mejadi fitur numerik menggunakan one hot encoding via multilabelbinarizerr kemudian di gabung pada data df_filtered"""

provinsi_encoded = pd.get_dummies(df_filtered['provinsi'], prefix='provinsi')

#gabungkan ke df_filtered
df_filtered = pd.concat([df_filtered, provinsi_encoded],axis = 1)
df_filtered.info()

"""mengubah column provinsi menjadi fitur numerik menggunakan one hot encoding dan digabungkan pada data df_filtered"""

# hitung threshold berdasarkan percentile
rating_threshold = df_filtered['rating'].quantile(0.7)  # Top 30% rating
review_threshold = df_filtered['jumlah_review'].quantile(0.7)  # Top 30% review

# Gabungan kriteria rating DAN jumlah review (lebih strict)
df_filtered['populer'] = ((df_filtered['rating'] >= rating_threshold) |
                          (df_filtered['jumlah_review'] >= review_threshold)).astype(int)

# Cek distribusi kelas
print("\nDistribusi Kelas Popularitas:")
print(df_filtered['populer'].value_counts(normalize=True))

"""mengubah masalah regresi (rating dan review) menjadi masalah klasifikasi biner dengan :
- 1 = populer
- 0 = tidak populer
"""

features = ["log_jumlah_review"] + list(mlb.classes_) + list(provinsi_encoded.columns)

x = pd.concat([df_filtered[["log_jumlah_review"]], kategori_encoded_df, provinsi_encoded], axis=1)
y = df_filtered["populer"]

"""menyiapkan data x dan y yang akan di masukan ke dalam model klasifikasi"""

# 3. Visualisasi Kriteria Popularitas
plt.figure(figsize=(10,6))
sns.scatterplot(data=df_filtered, x='jumlah_review', y='rating', hue='populer', alpha=0.6)
plt.xscale('log')
plt.title('Rating vs Jumlah Review (Setelah Kriteria Populer)')
plt.show()

"""visualisasi hasil dari hasil rating dan jumlah review"""

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""split data"""

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

"""menggunakan smote untuk menangani imbalanced"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""melakukan standarisasi pada fitur karena random forest dan decision tree tidak perlu standarisasi"""

from sklearn.model_selection import cross_val_score
from imblearn.pipeline import make_pipeline
models = {
    "Random Forest": (RandomForestClassifier(
        class_weight='balanced',
        max_depth=5,
        n_estimators=100
    ), False),

    "KNN": (make_pipeline(
        StandardScaler(),
        KNeighborsClassifier(weights='distance')  # Beri bobot oleh distance
    ), True),

    "SVM": (make_pipeline(
        StandardScaler(),
        SVC(class_weight='balanced', probability=True)
    ), True),

    "Logistic Regression": (make_pipeline(
        StandardScaler(),
        LogisticRegression(class_weight='balanced', max_iter=1000)
    ), True),

    "Decision Tree": (DecisionTreeClassifier(
        class_weight='balanced',
        max_depth=3
    ), False)
}

print("evaluasi model :")
print("="*20)

for name, (model, use_scaling) in models.items():
    print(f"model : {name}")
    if use_scaling:
      model.fit(X_train_resampled, y_train_resampled)
      y_pred = model.predict(X_test_scaled)
    else:
      model.fit(X_train_resampled, y_train_resampled)
      y_pred = model.predict(X_test)

    print("akurasi : ", accuracy_score(y_test, y_pred))
    print("f1_score : ", f1_score(y_test, y_pred) )
    print("clasifikasi report : \n", classification_report(y_test, y_pred))
    print("="*20)

    if name == "Random Forest":
      joblib.dump(model, "prediksi_popularitas.joblib")
      joblib.dump(scaler, "scaler_popularitas.joblib")
      joblib.dump(x.columns.tolist(), "features_popularis.joblib")
      joblib.dump(mlb, "mlb_populairatas.joblib")
      print("model berhasil disimpan")

"""1. Melatih dan mengevaluasi 5 algoritma klasifikasi.

2. Menampilkan hasil evaluasi menggunakan metrik:
  - Accuracy
  - F1-Score
  - Classification Report (Precision, Recall, F1, Support)

3. Menyimpan model terbaik (Random Forest) dan komponen penting lainnya.
"""

model_names = []
akurasi = []

for name, (model, use_scaling) in models.items():
    model_names.append(name)
    if use_scaling:
        y_pred = model.predict(X_test_scaled)
    else:
        y_pred = model.predict(X_test)
    akurasi.append(accuracy_score(y_test, y_pred))

plt.figure(figsize=(10, 6))
plt.bar(model_names, akurasi, color='skyblue')
plt.ylabel('akurasi')
plt.title('perbandingan peforma model')
plt.xticks(rotation=45)
plt.ylim(0,1)
plt.grid(True)
plt.show()

"""perbandingan evaluasi pada model"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

for name, (model, use_scaling) in models.items():
    if use_scaling:
        y_pred = model.predict(X_test_scaled)
    else:
        y_pred = model.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Tidak Populer', 'Populer'])
    disp.plot(cmap='Blues')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

"""- random forest = pada tp hanya 2, maksudnya dari total kesalahan hanya 2 yang populer itu salah, akan tetapi fp 43 dari 113 data populer ini salah
- knn = pada tp terdapat 34 kesalahan, yang mana ini mampu mendeteksi data populer tetapi banyak masalah, dan model ini kurang efektif
- svm = pada model ini sangat bermasalah karena fp terdapat 100 yang mana ini maksudnya model tidak mengenali tidak populer sama sekali
- logistic regresion = pada model ini fn 91 yang mana model tidak mengenali populer sama sekali karena model condong di tidak populer
- decision tree = pada model ini fn 0, maksudnya model membaca 100% akurat untuk tidak populer akan tetapi masih bermasalah pada fn masih terdapat masalah 45 data klasifikasi yang salah
"""

# roc curve dan auc score
from sklearn.metrics import roc_curve, auc

plt.figure(figsize=(8, 6))
for name, (model, use_scaling) in models.items():
    if hasattr(model, "predict_proba"):
        if use_scaling:
            y_proba = model.predict_proba(X_test_scaled)[:, 1]
        else:
            y_proba = model.predict_proba(X_test)[:, 1]

        fpr, tpr, _ = roc_curve(y_test, y_proba)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

"""| Model                   | AUC      | Evaluasi                                                            |
| ----------------------- | -------- | ------------------------------------------------------------------- |
| **Decision Tree**       | **0.84** | **Terbaik** dalam membedakan kelas, sangat baik untuk klasifikasi.  |
| **Random Forest**       | 0.81     | Hampir sebaik Decision Tree, performa stabil dan kuat.              |
| **Logistic Regression** | 0.61     | Di atas tebakan acak, tapi jauh lebih rendah dari model tree-based. |
| **KNN**                 | 0.60     | Performa buruk, hanya sedikit lebih baik dari tebakan acak.         |
| **SVM**                 | 0.59     | Hampir sama seperti KNN, **sangat tidak optimal** pada dataset ini. |

"""